#!/usr/bin/env python3
"""
Batch convert MySQL dumps (C1.sql .. C9.sql) in this folder to PostgreSQL-compatible SQL.
Rules:
- Convert MySQL backticks to double quotes for identifiers
- Remove MySQL-specific SET/ENGINE/CHARSET/COLLATE statements
- Convert `id` column to: integer GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
  (works whether or not AUTO_INCREMENT was present; preserves explicit id inserts)
- Keep multi-row INSERT statements as-is
- Append a sequence sync using setval() per table
Outputs alongside inputs as: <name>_postgres.sql
Usage: python3 convert_batch_mysql_to_postgres.py
"""

import os
import re
from pathlib import Path

SQL_DIR = Path(__file__).parent
INPUT_BASENAMES = [f"C{i}.sql" for i in range(1, 10)]

HEADER = (
    "-- PostgreSQL version of MySQL dump\n"
    "-- Converted by convert_batch_mysql_to_postgres.py\n\n"
)

# Simple helpers
REMOVE_LINES_PATTERNS = [
    r"^SET\s+[^;]*;\s*$",
    r"^START\s+TRANSACTION;\s*$",
    r"^COMMIT;\s*$",
    r"^/\*!40101[^;]*;\s*$",
    r"^/\*!.*\*/;?\s*$",
    r"^-- phpMyAdmin SQL Dump\s*$",
    r"^-- version .*$",
    r"^-- https://www\.phpmyadmin\.net/.*$",
    r"^-- Host: .*$",
    r"^-- Generation Time: .*$",
    r"^-- Server version: .*$",
    r"^-- PHP Version: .*$",
]

ENGINE_TAIL_RE = re.compile(r"\)\s*ENGINE=\w+(?:\s+DEFAULT\s+CHARSET=\w+)?(?:\s+COLLATE=[\w\-]+)?\s*;", re.IGNORECASE)
CHARSET_RE = re.compile(r"\s+DEFAULT\s+CHARSET=\w+", re.IGNORECASE)
COLLATE_RE = re.compile(r"\s+COLLATE=[\w\-]+", re.IGNORECASE)

CREATE_TABLE_RE = re.compile(r"CREATE\s+TABLE\s+`?([A-Za-z0-9_]+)`?\s*\(", re.IGNORECASE)
ID_COL_AUTO_RE = re.compile(r"`id`\s+int\(\d+\)\s+NOT\s+NULL\s+AUTO_INCREMENT", re.IGNORECASE)
ID_COL_INT_RE = re.compile(r"`id`\s+int\(\d+\)\s+NOT\s+NULL", re.IGNORECASE)
PRIMARY_KEY_LINE_RE = re.compile(r",\s*PRIMARY\s+KEY\s*\(\s*`id`\s*\)\s*", re.IGNORECASE)

BACKTICK_IDENT_RE = re.compile(r"`([^`]+)`")
INT_LEN_RE = re.compile(r"int\(\d+\)", re.IGNORECASE)


def convert_mysql_to_postgres(content: str) -> str:
    # Normalize line endings
    content = content.replace("\r\n", "\n").replace("\r", "\n")

    # Drop unwanted lines
    lines = []
    for line in content.splitlines():
        if any(re.match(pat, line) for pat in REMOVE_LINES_PATTERNS):
            continue
        lines.append(line)
    content = "\n".join(lines)

    # Remove trailing MySQL table options like ENGINE/CHARSET/COLLATE
    content = ENGINE_TAIL_RE.sub(") ;", content)
    content = CHARSET_RE.sub("", content)
    content = COLLATE_RE.sub("", content)

    # Identify table name (assume one table per file)
    m = CREATE_TABLE_RE.search(content)
    table_name = m.group(1) if m else None

    # Ensure id column is identity primary key
    def replace_id_column(match):
        return '"id" integer GENERATED BY DEFAULT AS IDENTITY'

    content = ID_COL_AUTO_RE.sub(replace_id_column, content)
    content = ID_COL_INT_RE.sub(replace_id_column, content)

    # Remove redundant PRIMARY KEY(id) if present; we'll add inline PK above
    content = PRIMARY_KEY_LINE_RE.sub("", content)

    # Convert remaining int(n) to INTEGER (but avoid modifying inside words)
    content = INT_LEN_RE.sub("INTEGER", content)

    # Upcast any VARCHAR(n) to TEXT to avoid truncation/length errors during import
    content = re.sub(r"varchar\s*\(\s*\d+\s*\)", "TEXT", content, flags=re.IGNORECASE)

    # Convert backticks to double quotes
    content = BACKTICK_IDENT_RE.sub(r'"\1"', content)

    # Add IF NOT EXISTS to CREATE TABLE (use callable to avoid literal backref output)
    content = re.sub(
        r'CREATE\s+TABLE\s+"([^"]+)"',
        lambda m: f'CREATE TABLE IF NOT EXISTS "{m.group(1)}"',
        content,
    )

    # Remove MySQL-style ALTER TABLE blocks (ADD KEY/MODIFY, AUTO_INCREMENT)
    # This removes any ALTER TABLE "table" ...; blocks entirely
    content = re.sub(r'(?ms)^ALTER\s+TABLE\s+"[^"]+"[\s\S]*?;\s*', '', content)

    # Fix MySQL-style escaped quotes in string literals: \' -> '' for PostgreSQL
    content = re.sub(r"\\'", "''", content)

    # Conservatively escape possessive/contraction apostrophes between alphanumerics: e.g., Minister's -> Minister''s
    content = re.sub(r"([A-Za-z0-9])'([A-Za-z0-9])", r"\1''\2", content)

    # Convert MySQL zero dates to NULL (invalid in PostgreSQL)
    content = re.sub(r"'0000-00-00(?: 00:00:00)?'", "NULL", content)

    # Split multi-row INSERT into single-row INSERTs to avoid parser issues with embedded sequences
    def split_multirow_insert(m: re.Match) -> str:
        head = m.group(1)
        values_blob = m.group(2).strip()
        # Split on top-level tuple separators. Good-enough heuristic for dumps without nested tuples.
        parts = re.split(r"\),\s*\n?\s*", values_blob)
        out_stmts = []
        for part in parts:
            p = part.strip()
            if not p:
                continue
            if not p.startswith('('):
                p = '(' + p
            if not p.endswith(')'):
                p = p + ')'
            out_stmts.append(f"{head}{p};")
        return "\n".join(out_stmts)

    content = re.sub(
        r"(?is)(INSERT\s+INTO\s+\"[^\"]+\"\s*\([^)]*\)\s*VALUES\s*)(.+?)\s*;",
        split_multirow_insert,
        content,
    )

    # Append sequence sync (setval) if we have a table name
    setval_sql = ""
    if table_name:
        quoted = f'"{table_name}"'
        setval_sql = (
            f"\n\n-- Keep sequence in sync after explicit id inserts\n"
            f"SELECT setval(pg_get_serial_sequence('{quoted}', 'id'), \n"
            f"       COALESCE((SELECT MAX(\"id\") FROM {quoted}), 1), true);\n"
        )

    return HEADER + content.strip() + setval_sql


def process_file(path: Path) -> Path:
    with path.open("r", encoding="utf-8") as f:
        content = f.read()
    converted = convert_mysql_to_postgres(content)
    out_path = path.with_name(path.stem + "_postgres.sql")
    with out_path.open("w", encoding="utf-8") as f:
        f.write(converted)
    return out_path


def main():
    found_any = False
    for name in INPUT_BASENAMES:
        in_path = SQL_DIR / name
        if not in_path.exists():
            continue
        found_any = True
        out_path = process_file(in_path)
        print(f"Converted {in_path.name} -> {out_path.name}")
    if not found_any:
        print("No C1.sql..C9.sql files found in this directory.")

if __name__ == "__main__":
    main()
